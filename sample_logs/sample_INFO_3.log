I0623 14:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 14:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 14:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 14:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 14:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 14:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 15:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 15:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 15:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 15:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 15:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 15:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 16:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 16:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 16:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 16:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 16:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 16:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 17:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 17:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 17:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 17:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 17:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 17:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 14:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 14:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 14:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 15:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 15:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 16:49:05.725900   162 mem_tracker.cc:912] Long wait for safe op id
I0623 14:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 14:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 14:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 14:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 15:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 15:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 15:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 15:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 15:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 15:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 17:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 17:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 17:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 17:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 17:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 17:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 15:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 15:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 16:44:05.725900   162 mem_tracker.cc:912] Number of aborted transactions not cleaned up on account of reaching size limits
I0623 14:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 14:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 14:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 14:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 14:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 14:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 14:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 15:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 15:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 15:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 15:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 15:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 15:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 15:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 15:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 15:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 14:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 16:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 16:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 16:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 16:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 16:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 16:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 17:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 17:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 17:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 17:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 17:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 17:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 17:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 17:45:05.725900   162 mem_tracker.cc:912] Rejecting CQL call: Soft memory limit exceeded (at 85.28% of capacity), score: 0.98
I0623 14:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 14:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 14:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 14:44:05.725900   162 mem_tracker.cc:912] SST files limit exceeded
I0623 14:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 14:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 14:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 14:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 14:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 14:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 14:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 16:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 16:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 16:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 16:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 16:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 16:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 16:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 16:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 16:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 15:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 15:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 15:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 15:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 15:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 15:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 15:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 15:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 15:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 17:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 17:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 17:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 17:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
I0623 17:49:05.725900   162 mem_tracker.cc:912] Too big clock skew is detected
Operation failed.*operation memory consumption.*has exceeded
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 14:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 15:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 17:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 17:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 17:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 17:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 17:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 16:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 16:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 16:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
I0623 16:49:05.725900   162 mem_tracker.cc:912] Operation failed operation memory consumption has exceeded its limit
W0623 14:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 14:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 14:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 14:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 14:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 14:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 14:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 14:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 14:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 17:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 17:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 17:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 17:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 17:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 17:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 17:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 17:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 17:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 16:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 16:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 16:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 16:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 16:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 16:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 16:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 16:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 16:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 15:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 15:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
W0623 15:20:39.374562  6320 column_family.cc:576] T 00000000000000000000000000000000 P 0b560d04e4d5427aafca43e986e2d849 [R]: [default] Stopping writes because we have 2 immutable memtables (waiting for flush), max_write_buffer_number is set to 2
I0623 14:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 14:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 16:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 17:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 15:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 14:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
I0623 14:44:05.725900   162 mem_tracker.cc:912] Soft memory limit exceeded
W0623 17:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 17:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 17:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 17:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 17:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 17:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 17:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 14:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 15:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 15:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 15:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 15:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 16:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 16:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 16:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 16:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 16:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 16:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 16:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 16:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W0623 16:22:45.356575  1104 consensus_peers.cc:477] T af10595a4011458bb046115676e95013 P def8f15085384bd3b0198e41f1c4710c -> Peer 401594316dcf4002ae277945dd8a1b9f ([host: "yb-tserver-19.yb-tservers.yb-prod-ros-pm-kobe.svc.uhn7kbfr5.local" port: 9100], [host: "240b:c020:10f:53f8:b453:2:2d:0" port: 9100]): Couldn't send request.  Status: Remote error (yb/rpc/outbound_call.cc:413): Service unavailable (yb/rpc/service_pool.cc:223): UpdateConsensus request on yb.consensus.ConsensusService from [240b:c010:207:5e73:b454:2:0:4487]:43417 dropped due to backpressure. The service queue is full, it has 5000 items.. Retrying in the next heartbeat period. Already tried 205 times. State: 2
W1005 22:40:26.164709 46581 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6453 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6453
W1005 22:40:26.164709 46581 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6453 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6453
W1005 22:40:26.164709 46581 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6453 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6453
W1005 22:40:26.164709 46581 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6453 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6453
W1005 22:40:26.164709 46581 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6453 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6453
W1005 22:40:26.164709 46581 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6453 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6453
W1005 22:40:59.996161 46580 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6456 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6456
W1005 22:41:10.657510 45382 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6456 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6456
W1005 22:41:25.566188 40807 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6458 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6458
W1005 22:42:00.388607 45391 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6460 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6460
W1005 22:42:44.949613 45983 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6464 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6464
W1005 22:43:01.687731 45382 replica_state.cc:804] T 245e1b04e4e44f30a330c17c93cdf895 P 2926dd087061477c9390b44846b549ab [term 6466 LEADER]: Can't advance the committed index across term boundaries until operations from the current term are replicated. Last committed operation was: { term: 1087 index: 13427855589 }, New majority replicated is: { term: 1087 index: 13427855589 }, Current term is: 6466